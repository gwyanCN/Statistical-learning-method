{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b381698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc255a1",
   "metadata": {},
   "source": [
    "# 利用朴素贝叶斯法进行手写数字集的模型建立\n",
    "### 准确率大概在80%左右"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9519fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  \\\n",
       "0      5  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "1      0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "2      4  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "3      1  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "4      9  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "...   .. .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "59995  8  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "59996  3  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "59997  5  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "59998  6  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "59999  8  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
       "\n",
       "       782  783  784  \n",
       "0        0    0    0  \n",
       "1        0    0    0  \n",
       "2        0    0    0  \n",
       "3        0    0    0  \n",
       "4        0    0    0  \n",
       "...    ...  ...  ...  \n",
       "59995    0    0    0  \n",
       "59996    0    0    0  \n",
       "59997    0    0    0  \n",
       "59998    0    0    0  \n",
       "59999    0    0    0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 载入数据 取1000个训练样本\n",
    "trainDataPd = pd.read_csv(\"trainData.csv\")\n",
    "trainDataPd.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8e3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = trainDataPd.iloc[:,:]\n",
    "labels,imgdata = trainData.iloc[:,0],trainData.iloc[:,1:]\n",
    "imgdata= imgdata.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb303035",
   "metadata": {},
   "source": [
    "## 计算p(y|x) = $\\frac{p(x,y)}{p(x)}$\n",
    "### 同时由于特征为多维特征,朴素贝叶斯有一个比较强的假设==>即输入特征之间相对独立(独立性假设)，即$p(x=x_0,x_1,x_2....|y=y_k)=p(x=x_0|y=y_k)*p(x=x_1|y=y_k)*p(x=x_2|y=y_k)....$\n",
    "\n",
    "#### 其中分母p(x)可按照全概率公式拆解为 $\\sum_{k=0}^{m}p(y=y_k)*p(x=x_0,x_1,x_2....|y=y_k)$\n",
    "#### 于是最后的计算变成了 p(y|x) = argmax $\\frac{p(x=x_0,x_1,x_2....|y=y_k)=p(x=x_0|y=y_k)*p(x=x_1|y=y_k)*p(x=x_2|y=y_k)....}{\\sum_{k=0}^{m}p(y=y_k)*p(x=x_0,x_1,x_2....|y=y_k}$\n",
    "#### 由于分母不变,求解可转换为 p(y|x) = argmax ${p(x=x_0,x_1,x_2....|y=y_k)=p(x=x_0|y=y_k)*p(x=x_1|y=y_k)*p(x=x_2|y=y_k)....}$\n",
    "\n",
    "#### p(y|x) = argmax ${p(x=x_0,x_1,x_2....|y=y_k)}$ = argmax $ {{p(y=y_k)*\\prod_{i=0}^n p(x=x_i|y=y_k)}}$\n",
    "\n",
    "#### 其中$p(x=x_i|y=y_k)=\\frac{\\sum_{j=1}^{n}I(x=x_i,y=y_k)}{\\sum_{j=1}^{n}I(y=y_k)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44113e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949],\n",
       "       dtype=int64),\n",
       " array([0.09873333, 0.11238333, 0.09931667, 0.1022    , 0.09738333,\n",
       "        0.09036667, 0.09865   , 0.10443333, 0.09753333, 0.09916667]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 计算每个类别的总数,然后计算每个特征的条件概率值\n",
    "Lambda = 0.00001  ##防止有些地方的概率值为0导致后续的概率计算被消除,当特征总数过大时，lambda的值尽量取小，减少影响\n",
    "YlabelCnt = np.array([np.sum(labels==i) for i in range(10)])\n",
    "py=(YlabelCnt+1)/(YlabelCnt.sum()+Lambda*YlabelCnt.shape[0]) # 获得p(y=y_k)的概率值\n",
    "YlabelCnt,py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f929967b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5923, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px_y = [imgdata[labels==index] for index,IY in enumerate(YlabelCnt)]## 获得y=yk所在的图像的所有特征\n",
    "px_y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d1fca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[9.99998678e-01, 9.99998678e-01, 9.99998678e-01, ...,\n",
       "         9.99998678e-01, 9.99998678e-01, 9.99998678e-01],\n",
       "        [1.68833138e-09, 1.68833138e-09, 1.68833138e-09, ...,\n",
       "         1.68833138e-09, 1.68833138e-09, 1.68833138e-09]]),\n",
       " array([[9.99998839e-01, 9.99998839e-01, 9.99998839e-01, ...,\n",
       "         9.99998839e-01, 9.99998839e-01, 9.99998839e-01],\n",
       "        [1.48323767e-09, 1.48323767e-09, 1.48323767e-09, ...,\n",
       "         1.48323767e-09, 1.48323767e-09, 1.48323767e-09]]),\n",
       " array([[9.99998686e-01, 9.99998686e-01, 9.99998686e-01, ...,\n",
       "         9.99998686e-01, 9.99998686e-01, 9.99998686e-01],\n",
       "        [1.67841337e-09, 1.67841337e-09, 1.67841337e-09, ...,\n",
       "         1.67841337e-09, 1.67841337e-09, 1.67841337e-09]]),\n",
       " array([[9.99998723e-01, 9.99998723e-01, 9.99998723e-01, ...,\n",
       "         9.99998723e-01, 9.99998723e-01, 9.99998723e-01],\n",
       "        [1.63105321e-09, 1.63105321e-09, 1.63105321e-09, ...,\n",
       "         1.63105321e-09, 1.63105321e-09, 1.63105321e-09]]),\n",
       " array([[9.99998660e-01, 9.99998660e-01, 9.99998660e-01, ...,\n",
       "         9.99998660e-01, 9.99998660e-01, 9.99998660e-01],\n",
       "        [1.71174026e-09, 1.71174026e-09, 1.71174026e-09, ...,\n",
       "         1.71174026e-09, 1.71174026e-09, 1.71174026e-09]]),\n",
       " array([[9.99998556e-01, 9.99998556e-01, 9.99998556e-01, ...,\n",
       "         9.99998556e-01, 9.99998556e-01, 9.99998556e-01],\n",
       "        [1.84467544e-09, 1.84467544e-09, 1.84467544e-09, ...,\n",
       "         1.84467544e-09, 1.84467544e-09, 1.84467544e-09]]),\n",
       " array([[9.99998677e-01, 9.99998677e-01, 9.99998677e-01, ...,\n",
       "         9.99998677e-01, 9.99998677e-01, 9.99998677e-01],\n",
       "        [1.68975782e-09, 1.68975782e-09, 1.68975782e-09, ...,\n",
       "         1.68975782e-09, 1.68975782e-09, 1.68975782e-09]]),\n",
       " array([[9.9999875e-01, 9.9999875e-01, 9.9999875e-01, ..., 9.9999875e-01,\n",
       "         9.9999875e-01, 9.9999875e-01],\n",
       "        [1.5961672e-09, 1.5961672e-09, 1.5961672e-09, ..., 1.5961672e-09,\n",
       "         1.5961672e-09, 1.5961672e-09]]),\n",
       " array([[9.99998662e-01, 9.99998662e-01, 9.99998662e-01, ...,\n",
       "         9.99998662e-01, 9.99998662e-01, 9.99998662e-01],\n",
       "        [1.70910726e-09, 1.70910726e-09, 1.70910726e-09, ...,\n",
       "         1.70910726e-09, 1.70910726e-09, 1.70910726e-09]]),\n",
       " array([[9.99998684e-01, 9.99998684e-01, 9.99998684e-01, ...,\n",
       "         9.99998684e-01, 9.99998684e-01, 9.99998684e-01],\n",
       "        [1.68095257e-09, 1.68095257e-09, 1.68095257e-09, ...,\n",
       "         1.68095257e-09, 1.68095257e-09, 1.68095257e-09]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lambda = 0.00001 ##防止有些地方的概率值为0导致后续的概率计算被消除,当特征总数过大时，lambda的值尽量取小，减少影响\n",
    "pxi_y = []\n",
    "for pxy in px_y:\n",
    "    cnt= pxy.shape[0]\n",
    "    pxiykCnt = np.zeros([2,784])\n",
    "    for i in range(784):\n",
    "        pxiykCnt[0][i]+=(np.sum(pxy[:,i]==0)+Lambda)/(pxy.shape[0]+Lambda*784)# 加入拉普拉斯平滑\n",
    "        pxiykCnt[1][i]+=(np.sum(pxy[:,i]==1)+Lambda)/(pxy.shape[0]+Lambda*784)# 加入拉普拉斯平滑\n",
    "    pxi_y.append(pxiykCnt)\n",
    "pxi_y## 获得每个p(xi=cj|y=yk)的条件概率值 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "465234b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99982984,\n",
       "        0.99982984, 0.99982984, 0.99999868, 0.99982984, 0.99982984,\n",
       "        0.99982984, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99982984,\n",
       "        0.99982984, 0.99999868, 0.99982984, 0.99966101, 0.99982984,\n",
       "        0.99999868, 0.99999868, 0.99982984, 0.99966101, 0.99932335,\n",
       "        0.99966101, 0.99966101, 0.99932335, 0.99949218, 0.99982984,\n",
       "        0.99982984, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99982984, 0.99966101, 0.99966101,\n",
       "        0.99966101, 0.99949218, 0.99881685, 0.99712851, 0.99459602,\n",
       "        0.99037519, 0.98412836, 0.9772062 , 0.97214121, 0.96943988,\n",
       "        0.96910221, 0.97366071, 0.97788154, 0.98362186, 0.98818036,\n",
       "        0.99273885, 0.99729735, 0.99847918, 0.99982984, 0.99982984,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99966101, 0.99932335, 0.99898568, 0.99679085, 0.99358302,\n",
       "        0.98446603, 0.96656972, 0.93179009, 0.87658165, 0.79756775,\n",
       "        0.71973567, 0.64342309, 0.59142248, 0.57285084, 0.59783814,\n",
       "        0.65996874, 0.74252814, 0.83167204, 0.90258196, 0.95255657,\n",
       "        0.98311536, 0.99695968, 0.99966101, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99949218, 0.99881685,\n",
       "        0.99695968, 0.99223235, 0.9792322 , 0.95036174, 0.8976858 ,\n",
       "        0.8044899 , 0.68411188, 0.54803237, 0.40925153, 0.30727631,\n",
       "        0.23805473, 0.22150908, 0.24852238, 0.32838046, 0.46074564,\n",
       "        0.6083058 , 0.75282696, 0.87421799, 0.9532319 , 0.99240119,\n",
       "        0.99966101, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99746618, 0.99273885, 0.9832842 ,\n",
       "        0.95103707, 0.89836113, 0.79891841, 0.65254008, 0.49248627,\n",
       "        0.3434066 , 0.23349623, 0.15498882, 0.10974154, 0.09826089,\n",
       "        0.10906621, 0.15431349, 0.25696404, 0.41887502, 0.59446148,\n",
       "        0.76396995, 0.8951533 , 0.98108937, 0.99881685, 0.99966101,\n",
       "        0.99982984, 0.99999868, 0.99999868, 0.99999868, 0.99982984,\n",
       "        0.99746618, 0.98834919, 0.96606322, 0.90882878, 0.80685357,\n",
       "        0.66013757, 0.48894077, 0.32584796, 0.20648293, 0.14350817,\n",
       "        0.11480654, 0.10433888, 0.09910505, 0.0886374 , 0.09437773,\n",
       "        0.1462095 , 0.26658753, 0.44318699, 0.63987759, 0.82339922,\n",
       "        0.95779039, 0.99797268, 0.99982984, 0.99982984, 0.99982984,\n",
       "        0.99999868, 0.99966101, 0.99949218, 0.99695968, 0.98210237,\n",
       "        0.93398492, 0.83791887, 0.69711203, 0.52473339, 0.3484716 ,\n",
       "        0.22353508, 0.15481999, 0.15448232, 0.18385929, 0.20766476,\n",
       "        0.21441809, 0.18656062, 0.15211866, 0.13540418, 0.18656062,\n",
       "        0.3143673 , 0.52355156, 0.73898265, 0.92976409, 0.99797268,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99966101,\n",
       "        0.99949218, 0.99476485, 0.96049172, 0.88367265, 0.74083981,\n",
       "        0.57065601, 0.3780174 , 0.23602873, 0.16343048, 0.17440463,\n",
       "        0.24143139, 0.32061413, 0.38595256, 0.39827737, 0.3770044 ,\n",
       "        0.29106833, 0.20209327, 0.16917081, 0.23991189, 0.42056335,\n",
       "        0.65000758, 0.8966728 , 0.99746618, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99982984, 0.99949218, 0.99138819,\n",
       "        0.9257121 , 0.80719123, 0.6312671 , 0.435083  , 0.26793819,\n",
       "        0.16663831, 0.17389813, 0.25865237, 0.37126407, 0.4906291 ,\n",
       "        0.58399383, 0.62215012, 0.58196783, 0.45888847, 0.30423732,\n",
       "        0.19044378, 0.20310627, 0.35066643, 0.57268201, 0.85817884,\n",
       "        0.99594668, 0.99999868, 0.99999868, 0.99999868, 0.99982984,\n",
       "        0.99999868, 0.99982984, 0.98294653, 0.87911415, 0.71770967,\n",
       "        0.50818775, 0.32179596, 0.18791128, 0.17001497, 0.24598988,\n",
       "        0.3764979 , 0.52608406, 0.66165707, 0.75755429, 0.78456759,\n",
       "        0.73746315, 0.58737049, 0.39101755, 0.22285974, 0.18132679,\n",
       "        0.30997764, 0.51899307, 0.82137322, 0.99425835, 0.99982984,\n",
       "        0.99999868, 0.99999868, 0.99982984, 0.99982984, 0.99982984,\n",
       "        0.96943988, 0.81326923, 0.62147478, 0.40047221, 0.22860007,\n",
       "        0.16258631, 0.22336624, 0.35843275, 0.52827889, 0.68951454,\n",
       "        0.81968489, 0.88417915, 0.88654281, 0.81884072, 0.66503373,\n",
       "        0.45078448, 0.2573017 , 0.18791128, 0.28819817, 0.49890192,\n",
       "        0.79655475, 0.99155702, 0.99982984, 0.99999868, 0.99999868,\n",
       "        0.99982984, 0.99966101, 0.99949218, 0.95306307, 0.74978797,\n",
       "        0.52540873, 0.30660098, 0.17643063, 0.18520995, 0.30187365,\n",
       "        0.47948611, 0.67735855, 0.82542521, 0.91625744, 0.94377724,\n",
       "        0.93077709, 0.84568519, 0.69221587, 0.47897961, 0.27165252,\n",
       "        0.19398928, 0.29174366, 0.50396692, 0.79013909, 0.99003752,\n",
       "        0.99982984, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99966101, 0.92385493, 0.66807273, 0.42478418, 0.23248323,\n",
       "        0.15971615, 0.23940539, 0.40823853, 0.61438379, 0.8080354 ,\n",
       "        0.91558211, 0.96099822, 0.96285539, 0.93043943, 0.82458105,\n",
       "        0.6618259 , 0.44673248, 0.26371736, 0.20546993, 0.31706863,\n",
       "        0.52929189, 0.79942491, 0.99020636, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99915451, 0.89380263,\n",
       "        0.59851348, 0.36248475, 0.19213211, 0.16343048, 0.29444499,\n",
       "        0.50126559, 0.72699549, 0.88417915, 0.95542673, 0.97112821,\n",
       "        0.95694623, 0.89684163, 0.76143745, 0.5762275 , 0.38038106,\n",
       "        0.23805473, 0.22235324, 0.35015993, 0.57014951, 0.81732122,\n",
       "        0.98986869, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99847918, 0.86121784, 0.53705821, 0.3199388 ,\n",
       "        0.16663831, 0.18098913, 0.35032876, 0.58990299, 0.79841191,\n",
       "        0.92081594, 0.96521905, 0.95846573, 0.90899762, 0.80887957,\n",
       "        0.64392959, 0.46344697, 0.30187365, 0.2068206 , 0.25747054,\n",
       "        0.41330352, 0.63076061, 0.84855535, 0.99172585, 0.99999868,\n",
       "        0.99982984, 0.99999868, 0.99999868, 0.99999868, 0.99763501,\n",
       "        0.8401137 , 0.50970725, 0.30069182, 0.15988498, 0.19145678,\n",
       "        0.38122523, 0.62231895, 0.82272388, 0.90984178, 0.92925759,\n",
       "        0.8946468 , 0.80161974, 0.66452723, 0.49231743, 0.33749744,\n",
       "        0.22336624, 0.21289859, 0.31774397, 0.50649942, 0.70825502,\n",
       "        0.89008831, 0.99476485, 0.99999868, 0.99982984, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99797268, 0.83200971, 0.50987608,\n",
       "        0.30069182, 0.16089798, 0.18841778, 0.36012109, 0.57740933,\n",
       "        0.75383996, 0.82897071, 0.82272388, 0.74658014, 0.62637094,\n",
       "        0.48269394, 0.33344545, 0.22471691, 0.19297628, 0.26473036,\n",
       "        0.42275818, 0.60999413, 0.79419108, 0.92925759, 0.99712851,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99982984, 0.99982984,\n",
       "        0.99662202, 0.83572403, 0.54735704, 0.32922462, 0.17406697,\n",
       "        0.16157331, 0.26793819, 0.42832967, 0.56120135, 0.62113712,\n",
       "        0.60357847, 0.52608406, 0.41144636, 0.30018532, 0.2053011 ,\n",
       "        0.17457347, 0.22792474, 0.37970573, 0.55765586, 0.73155399,\n",
       "        0.87793232, 0.96505022, 0.99864801, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99982984, 0.99982984, 0.99662202, 0.864088  ,\n",
       "        0.60965646, 0.38780972, 0.20411927, 0.12730019, 0.14283284,\n",
       "        0.21408042, 0.28921117, 0.32517263, 0.32449729, 0.27992534,\n",
       "        0.21171676, 0.16579414, 0.15245633, 0.21728825, 0.36366658,\n",
       "        0.54178554, 0.69880036, 0.84619169, 0.94073825, 0.98682969,\n",
       "        0.99915451, 0.99982984, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99982984, 0.99746618, 0.90156896, 0.70690435, 0.48640827,\n",
       "        0.2878605 , 0.15043033, 0.08374124, 0.07884508, 0.10028689,\n",
       "        0.12037803, 0.12713135, 0.12358586, 0.1197027 , 0.14604067,\n",
       "        0.22893774, 0.37092641, 0.53773355, 0.70251469, 0.83184087,\n",
       "        0.92891993, 0.97805037, 0.99560902, 0.99966101, 0.99949218,\n",
       "        0.99982984, 0.99999868, 0.99999868, 0.99999868, 0.99831035,\n",
       "        0.94698507, 0.81698356, 0.64072176, 0.44436882, 0.27587335,\n",
       "        0.15667715, 0.09505306, 0.07766325, 0.08103991, 0.09927389,\n",
       "        0.12932619, 0.19061261, 0.292419  , 0.4376155 , 0.59057832,\n",
       "        0.73695665, 0.85733468, 0.93668625, 0.97518021, 0.99476485,\n",
       "        0.99763501, 0.99949218, 0.99949218, 0.99982984, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99982984, 0.9837907 , 0.92537443,\n",
       "        0.81765889, 0.67296889, 0.52034373, 0.38173173, 0.28043184,\n",
       "        0.23552223, 0.23366506, 0.26523686, 0.34002994, 0.44909615,\n",
       "        0.56711051, 0.69660553, 0.80786657, 0.89971179, 0.95812806,\n",
       "        0.9848037 , 0.99544018, 0.99814151, 0.99915451, 0.99966101,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99797268, 0.98885569, 0.97129704, 0.93516675,\n",
       "        0.89127014, 0.84230853, 0.80668474, 0.78119093, 0.77426877,\n",
       "        0.78997025, 0.81597056, 0.85362035, 0.8946468 , 0.93162126,\n",
       "        0.96133589, 0.98294653, 0.99375185, 0.99831035, 0.99932335,\n",
       "        0.99966101, 0.99966101, 0.99982984, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99982984, 0.99949218, 0.99831035, 0.99746618,\n",
       "        0.99679085, 0.99662202, 0.99679085, 0.99729735, 0.99763501,\n",
       "        0.99814151, 0.99898568, 0.99966101, 0.99982984, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868, 0.99999868,\n",
       "        0.99999868, 0.99999868, 0.99999868, 0.99999868]),\n",
       " 0.09873333316877778)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxi_y[0][0],py[0]## 抽取一个观察统计的概率情况,p(xi=0,y=0) p(y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd02c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 获得模型 p(xi=cj,y=y_k)，即pxi_y\n",
    "# 加载测试集用于测试模型\n",
    "testData = pd.read_csv(\"testData.csv\")\n",
    "Testlabel = testData.iloc[:2000,0] # 取2000个测试样本点\n",
    "testVector = testData.iloc[:2000,1:].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9f66d2",
   "metadata": {},
   "source": [
    "###### 给定p(y|x) =  argmax ${p(x=x_0,x_1,x_2....|y=y_k)= argmax \\prod_{i=0}^n p(x=x_i|y=y_k)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13909344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YGW\\AppData\\Local\\Temp/ipykernel_10928/2968230501.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  with tqdm(total=testVector.shape[0]) as bar:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac119cb19f34e278c71f5c82ae66069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 对于每个样本点进行测试\n",
    "labelsPre=[]\n",
    "with tqdm(total=testVector.shape[0]) as bar:\n",
    "    for vetor in testVector:\n",
    "        inference=[]\n",
    "        for cls,yk in enumerate(py):\n",
    "            p=1.0\n",
    "            for index,point in enumerate(vetor):# 从第1个特征向量到第784个特征向量分别验证\n",
    "                p*=np.double(pxi_y[cls][int(point)][index]) # p(y=yk,xi=c) # 由于数值太小,计算器容易数值溢出，因此乘以10进行适当的放大\n",
    "            inference.append(p*yk)\n",
    "        label = np.argmax(np.array(inference))\n",
    "        labelsPre.append(label)\n",
    "        bar.update(1)\n",
    "        bar.set_postfix({\"labels:\":labelsPre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aee2502a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsPre=np.array(labelsPre).reshape(1,-1)\n",
    "labelsPre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65e73d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testlabel=Testlabel.to_numpy().reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "247c2e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Testlabel==labelsPre)/Testlabel.shape[1] *100 ### 预测正确率 # 样本集的增大也会提升准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253dcde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac0a13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ca683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
